{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8b9807",
   "metadata": {},
   "source": [
    "### Cell 1 - Necessary Libraries Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a25a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c89751",
   "metadata": {},
   "source": [
    "### Cell 2 - Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Finalized_dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15b4d8",
   "metadata": {},
   "source": [
    "### Cell 3 - Setting Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['Affinity'])\n",
    "y = dataset['Affinity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e521d",
   "metadata": {},
   "source": [
    "### Cell 4 - Converting the dataframe into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95847df",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_prefix = 'canonical_'\n",
    "isomeric_prefix = 'isomeric_'\n",
    "sequence_prefix =  'sequence_'\n",
    "\n",
    "def parse_and_convert(df, prefix):\n",
    "    cols = df.filter(regex=f'^{prefix}').columns\n",
    "    print(f\"Parsing {len(cols)} columns with prefix '{prefix}'\")\n",
    "\n",
    "    parsed_cols = []\n",
    "    for col in cols:\n",
    "        def safe_parse(x):\n",
    "            if pd.isna(x):\n",
    "                return []\n",
    "            \n",
    "            if isinstance(x, list):\n",
    "                return x\n",
    "            \n",
    "            if isinstance(x, (int, float)):\n",
    "                return [x]\n",
    "            \n",
    "            try:\n",
    "                obj = ast.literal_eval(x)\n",
    "                if isinstance(obj, list):\n",
    "                    return obj\n",
    "                if isinstance(obj, (int, float)):\n",
    "                    return [obj]\n",
    "                return []\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: failed parsing in column {col}: {x}. Error: {e}\")\n",
    "                return []\n",
    "\n",
    "        parsed_col = df[col].apply(safe_parse)\n",
    "\n",
    "        \n",
    "        max_len = max(parsed_col.apply(len).max(), 1)\n",
    "\n",
    "        def pad_list(lst):\n",
    "            return [float(i) for i in lst] + [0.0] * (max_len - len(lst))\n",
    "\n",
    "        padded_lists = parsed_col.apply(pad_list).tolist()\n",
    "        arr = np.array(padded_lists, dtype=np.float32)\n",
    "        parsed_cols.append(arr)\n",
    "\n",
    "    combined_array = np.hstack(parsed_cols)\n",
    "    return combined_array\n",
    "\n",
    "X_canonical_parsed = parse_and_convert(X, 'canonical_')\n",
    "X_isomeric_parsed = parse_and_convert(X, 'isomeric_')\n",
    "X_sequence_parsed = parse_and_convert(X, 'sequence_')\n",
    "\n",
    "print(f\"Parsed canonical features shape: {X_canonical_parsed.shape}\")\n",
    "print(f\"Parsed isomeric features shape: {X_isomeric_parsed.shape}\")\n",
    "print(f\"Parsed sequence features shape: {X_sequence_parsed.shape}\")\n",
    "\n",
    "X_canonical = X_canonical_parsed.astype(np.float32)\n",
    "X_isomeric = X_isomeric_parsed.astype(np.float32)\n",
    "X_sequence = X_sequence_parsed.astype(np.float32)\n",
    "\n",
    "X_canonical = np.array(X_canonical, dtype=np.float32)\n",
    "X_isomeric = np.array(X_isomeric, dtype=np.float32)\n",
    "X_sequence = np.array(X_sequence, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a510b",
   "metadata": {},
   "source": [
    "### Cell 5 - Splitting Data for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_canonical_train, X_canonical_test,\n",
    "    X_isomeric_train, X_isomeric_test,\n",
    "    X_sequence_train, X_sequence_test,\n",
    "    y_train, y_test) = train_test_split(X_canonical, X_isomeric, X_sequence,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b490425",
   "metadata": {},
   "source": [
    "### Cell 6 - Building DeepDTA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_model(input_shapes):\n",
    "    canonical_shape, isomeric_shape, sequence_shape = input_shapes\n",
    "\n",
    "    input_canonical = Input(shape=(canonical_shape,), name='canonical_input')\n",
    "    input_isomeric = Input(shape=(isomeric_shape,), name='isomeric_input')\n",
    "    input_sequence = Input(shape=(sequence_shape,), name='sequence_input')\n",
    "\n",
    "    def branch(input_layer):\n",
    "        x = Dense(256, activation='relu')(input_layer)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        return x\n",
    "    \n",
    "    branch_canonical = branch(input_canonical)\n",
    "    branch_isomeric = branch(input_isomeric)\n",
    "    branch_sequence = branch(input_sequence)\n",
    "\n",
    "    concatenated = Concatenate()([branch_canonical, branch_isomeric, branch_sequence])\n",
    "\n",
    "    x = Dense(128, activation='relu')(concatenated)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[input_canonical,input_isomeric,input_sequence], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = multi_input_model(\n",
    "    (X_canonical.shape[1], X_isomeric.shape[1], X_sequence.shape[1])\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25036d1f",
   "metadata": {},
   "source": [
    "### Cell 7 - Fitting and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_canonical_train,X_isomeric_train,X_sequence_train], y_train, validation_split=0.1,epochs=20,batch_size=20,verbose=1)\n",
    "\n",
    "test_loss, test_mae = model.evaluate(\n",
    "    [X_canonical_test, X_isomeric_test, X_sequence_test],\n",
    "    y_test\n",
    ")\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
